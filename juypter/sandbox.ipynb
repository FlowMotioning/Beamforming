{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sandbox Environment to test out function functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyBF library\n",
    "import numpy as np\n",
    "import sys, os\n",
    "'''\n",
    "import sys, os\n",
    "look here if below import doesn't work: https://stackoverflow.com/questions/7505988/importing-from-a-relative-path-in-python\n",
    "'''\n",
    "# sys.path.append('../jupyter')\n",
    "sys.path.append('.')\n",
    "from pybf.pybf.io_interfaces import DataLoader\n",
    "from pybf.scripts.beamformer_DAS_ref import BFCartesianReference\n",
    "from pybf.scripts.beamformer_mvbf_spatial_smooth import BFMVBFspatial\n",
    "from pybf.scripts.beamformer_mvbf_DCR import BFMVBFdcr\n",
    "from pybf.pybf.image_settings import ImageSettings\n",
    "from pybf.pybf.visualization import plot_image\n",
    "from pybf.scripts.picmus_eval import PicmusEval\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute path to the current notebook: c:\\Vault\\Documents\\_RealLifeFolder\\_School\\_ETH\\Bachelor of Science\\7. Semester\\P&S\\Wearable Ultrasound\\Beamforming\\juypter\n"
     ]
    }
   ],
   "source": [
    "# Get the absolute path to the current Jupyter notebook\n",
    "notebook_path = os.path.abspath(\"\")\n",
    "print(\"Absolute path to the current notebook:\", notebook_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('../python/')\n",
    "notebook_path = os.path.abspath(\"\")\n",
    "library_path = os.path.join(notebook_path, '../python')\n",
    "sys.path.append(library_path)\n",
    "\n",
    "from PICMUS_beamformer import create_beamformer, run_beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_obj = DataLoader('./pybf/tests/data/Picmus/resolution_distorsion/rf_dataset.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest resolution for the system is:  (633, 205)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delays precalculation...\n",
      "TX strategy: plane waves\n",
      "Number of plane waves:  75\n",
      "Maximum angle:  16.0 Â°\n",
      "Apodization precalculation...\n"
     ]
    }
   ],
   "source": [
    "bf, rf_data = create_beamformer(tx_strategy = ['PW_75_16', data_loader_obj.tx_strategy[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beamforming...\n",
      " \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (80, 240000) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_beamformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Vault\\Documents\\_RealLifeFolder\\_School\\_ETH\\Bachelor of Science\\7. Semester\\P&S\\Wearable Ultrasound\\Beamforming\\juypter\\../python\\PICMUS_beamformer.py:115\u001b[0m, in \u001b[0;36mrun_beamformer\u001b[1;34m(bf, rf_data, active_elements)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03mRuns the beamformer on the specified RF data.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    - The returned image is the beamformed image of the specified RF data.\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Run beamformer\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m img_data \u001b[38;5;241m=\u001b[39m \u001b[43mbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeamform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactive_elements\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img_data\n",
      "File \u001b[1;32mc:\\Vault\\Documents\\_RealLifeFolder\\_School\\_ETH\\Bachelor of Science\\7. Semester\\P&S\\Wearable Ultrasound\\Beamforming\\juypter\\pybf\\scripts\\beamformer_DAS_ref.py:117\u001b[0m, in \u001b[0;36mBFCartesianReference.beamform\u001b[1;34m(self, rf_data, numba_active)\u001b[0m\n\u001b[0;32m    113\u001b[0m     das_out[i,:], raw_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delay_and_sum(rf_data_proc_trans, \n\u001b[0;32m    114\u001b[0m                                            delays_samples\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, delays_samples\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf_data\u001b[38;5;241m.\u001b[39mappend(raw_data)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbf_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Coherent compounding\u001b[39;00m\n\u001b[0;32m    120\u001b[0m das_out_compound \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(das_out[acqs_to_process, :], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (80, 240000) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "run_beamformer(bf, rf_data, np.arange(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 32, 3328)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_data[:, np.arange(32)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img Data for Beamformer 1\n",
      "Beamforming...\n",
      " \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (242, 240000) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# beamformer 1\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImg Data for Beamformer 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m img_data \u001b[38;5;241m=\u001b[39m \u001b[43mbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeamform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumba_active\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Vault\\Documents\\_RealLifeFolder\\_School\\_ETH\\Bachelor of Science\\7. Semester\\P&S\\Wearable Ultrasound\\Beamforming\\juypter\\pybf\\scripts\\beamformer_DAS_ref.py:117\u001b[0m, in \u001b[0;36mBFCartesianReference.beamform\u001b[1;34m(self, rf_data, numba_active)\u001b[0m\n\u001b[0;32m    113\u001b[0m     das_out[i,:], raw_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delay_and_sum(rf_data_proc_trans, \n\u001b[0;32m    114\u001b[0m                                            delays_samples\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, delays_samples\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf_data\u001b[38;5;241m.\u001b[39mappend(raw_data)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbf_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Coherent compounding\u001b[39;00m\n\u001b[0;32m    120\u001b[0m das_out_compound \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(das_out[acqs_to_process, :], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (242, 240000) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# beamformer 1\n",
    "print(\"Img Data for Beamformer 1\")\n",
    "img_data = bf.beamform(rf_data, numba_active=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 already in grp\n"
     ]
    }
   ],
   "source": [
    "# Open the image database with write tags\n",
    "with h5py.File('image_database.hdf5', 'a') as f:\n",
    "    # open group for image data\n",
    "    if 'image_data' not in f:\n",
    "        grp = f.create_group('image_data')\n",
    "    else:\n",
    "        grp = f['image_data']\n",
    "\n",
    "    if '1' not in grp:\n",
    "        grp.create_dataset('1', data='data1')\n",
    "    else:\n",
    "        print(\"1 already in grp\")\n",
    "\n",
    "    \n",
    "\n",
    "# write image data and label it\n",
    "# write rendered image too\n",
    "\n",
    "# |label|image data|rendered image|\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element with key '1': <HDF5 dataset \"1\": shape (), type \"|O\">\n",
      "Element with key '3': <HDF5 dataset \"3\": shape (), type \"|O\">\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF5 file\n",
    "with h5py.File('image_database.hdf5', 'r') as f:\n",
    "    # Access the group\n",
    "    grp = f['image_data']\n",
    "    \n",
    "    # Get the keys of the elements in the group\n",
    "    keys = list(grp.keys())\n",
    "    \n",
    "    # Access the elements using the keys\n",
    "    for key in keys:\n",
    "        element = grp[key]\n",
    "        print(f\"Element with key '{key}': {element}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image database with write tags\n",
    "with h5py.File('image_database.hdf5', 'a') as f:\n",
    "    # Write image data and label it\n",
    "    grp = f['image_data']\n",
    "\n",
    "    grp.create_dataset('3', data='data2')\n",
    "\n",
    "# write image data and label it\n",
    "# write rendered image too\n",
    "\n",
    "# |label|image data|rendered image|\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Open the image database with write tags\n",
    "with h5py.File('image_database.hdf5', 'w') as f:\n",
    "    # Write image data and label it\n",
    "    f.create_dataset('image_data/1', data=\"test\")\n",
    "    f.create_dataset('label', data='image_label')\n",
    "    # Write rendered image\n",
    "    f.create_dataset('rendered_image', data=\"this is a rendered image\")\n",
    "\n",
    "\n",
    "\n",
    "# write image data and label it\n",
    "# write CNR and FWHM\n",
    "# dictionary with {'full': 1}\n",
    "# write rendered image too\n",
    "\n",
    "# |label|image data|rendered image|\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
     ]
    }
   ],
   "source": [
    "string_list = [str(i) for i in range(1, 101)]\n",
    "print(string_list)\n",
    "integer_list = list(range(1, 101))\n",
    "print(integer_list)\n",
    "\n",
    "\n",
    "# Open the image database with write tags\n",
    "# 'w' overwrites the file\n",
    "# 'a' appends to the file\n",
    "with h5py.File('image_database.hdf5', 'w') as f:\n",
    "    # open image data group\n",
    "    if 'image_data' not in f:\n",
    "        grp = f.create_group('image_data')\n",
    "    else:\n",
    "        grp = f['image_data']\n",
    "\n",
    "\n",
    "    # for loop going over all images\n",
    "    for i, value in enumerate(string_list):\n",
    "        # create dataset for image\n",
    "        if value not in grp:\n",
    "            grp.create_dataset(value, data=integer_list[i])\n",
    "        else:\n",
    "            print(f\"{i} already in grp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full', 'every 2nd', 'every 3rd', 'every 4th', 'every 5th', 'every 6th', 'every 7th', 'every 8th', 'every 9th', 'every 10th', '90% from middle', '80% from middle', '70% from middle', '60% from middle', '50% from middle', '40% from middle', '30% from middle', '20% from middle', '10% from middle']\n",
      "['100% of plane wave angles', '90% of angles', '80% of angles', '70% of angles', '60% of angles', '50% of angles', '40% of angles', '30% of angles', '20% of angles', '10% of angles']\n"
     ]
    }
   ],
   "source": [
    "# below code generates list containting names of all versions of the images\n",
    "# under each plane wave angle (folder) will be the range of different transducer counts\n",
    "\n",
    "every_nth = ['2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']\n",
    "# percent_from = ['10', '20', '30', '40', '50', '60', '70', '80', '90']\n",
    "# percent_from = percent_from[::-1]\n",
    "percent_from = ['90', '80', '70', '60', '50', '40', '30', '20', '10']\n",
    "\n",
    "# Trials using different count of transducers\n",
    "transducer_trials = ['full']\n",
    "\n",
    "# For loop to concatenate each string with the suffix\n",
    "for string in every_nth:\n",
    "    concatenated_string = 'every ' + string\n",
    "    transducer_trials.append(concatenated_string)\n",
    "\n",
    "for string in percent_from:\n",
    "    concatenated_string = string + '% from middle'\n",
    "    transducer_trials.append(concatenated_string)\n",
    "\n",
    "# Print the concatenated strings\n",
    "print(transducer_trials)\n",
    "\n",
    "# Trials using different amounts of plane wave angles\n",
    "angle_trials = ['100% of plane wave angles']\n",
    "\n",
    "for string in percent_from:\n",
    "    concatenated_string = string + '% of angles'\n",
    "    angle_trials.append(concatenated_string)\n",
    "\n",
    "# Print the concatenated strings\n",
    "print(angle_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next up: generate all the configurations (as arguments) for the beamformer in a list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wups",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
